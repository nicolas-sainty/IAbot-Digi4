import os
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.schema import AIMessage, HumanMessage
from dotenv import load_dotenv
from supabase import create_client
from typing import List

# Charger les variables d'environnement
load_dotenv()

SUPABASE_URL = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.getenv("NEXT_PUBLIC_SUPABASE_ANON_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# VÃ©rification des clÃ©s essentielles
if not SUPABASE_URL or not SUPABASE_KEY or not OPENAI_API_KEY:
    raise ValueError("VÃ©rifiez que SUPABASE_URL, SUPABASE_KEY et OPENAI_API_KEY sont dÃ©finis dans votre fichier .env")

# Initialiser Supabase et Embeddings
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# ğŸ“Œ Fonction pour rÃ©cupÃ©rer l'historique du chat
def get_chat_history(chat_id: str) -> List:
    """
    RÃ©cupÃ¨re l'historique des messages pour un chat_id donnÃ©.
    """
    response = supabase.table("message").select("*").eq("chat_id", chat_id).order("id").execute()

    # âœ… VÃ©rifier si Supabase a retournÃ© une erreur correctement
    if "error" in response and response["error"]:
        raise Exception(f"Erreur Supabase : {response['error']}")

    # âœ… VÃ©rifier si des donnÃ©es ont Ã©tÃ© retournÃ©es
    if not response.data or len(response.data) == 0:
        print("âš ï¸ Aucun message trouvÃ© pour ce chat_id.")
        return []

    # âœ… Transformer les messages en format LangChain
    messages = response.data
    history = []
    for message in messages:
        if message["role"] == "user":
            history.append(HumanMessage(content=message["content"]))
        elif message["role"] == "assistant":
                history.append(AIMessage(content=message["content"]))
        
        return history


# ğŸ“Œ Fonction pour rÃ©cupÃ©rer le dernier message utilisateur
def get_last_user_message() -> dict:
    """
    RÃ©cupÃ¨re le dernier message utilisateur dans la base de donnÃ©es.
    """
    response = supabase.table("message").select("*").eq("role", "user").order("id", desc=True).limit(1).execute()

    print("ğŸ” Debug - DonnÃ©es rÃ©cupÃ©rÃ©es depuis Supabase:", response.data)  # âœ Ajout pour voir le contenu

    # VÃ©rifier si Supabase a retournÃ© une erreur
    if hasattr(response, "error") and response.error:
        raise Exception(f"Erreur Supabase : {response.error}")

    # VÃ©rifier si des donnÃ©es ont Ã©tÃ© retournÃ©es
    if not response.data or len(response.data) == 0:
        print("âš ï¸ Aucun message utilisateur trouvÃ©.")
        return None

    return response.data[0]

# ğŸ“Œ Fonction pour sauvegarder une rÃ©ponse d'assistant
def save_assistant_message(chat_id: str, content: str):
    """
    Sauvegarde une rÃ©ponse de l'assistant dans la base de donnÃ©es.
    """
    response = supabase.table("message").insert({
        "chat_id": chat_id,
        "role": "assistant",
        "content": content
    }).execute()

    # âœ… VÃ©rifier si Supabase a retournÃ© une erreur
    if isinstance(response, dict) and "error" in response:
        raise Exception(f"Erreur Supabase : {response['error']}")

    # âœ… VÃ©rifier si l'insertion a bien fonctionnÃ©
    if not response.data:
        raise Exception("âš ï¸ L'insertion dans la table 'message' a Ã©chouÃ©.")
    
    print("âœ… RÃ©ponse de l'assistant sauvegardÃ©e avec succÃ¨s.")


# ğŸ“Œ Fonction pour crÃ©er le chatbot
def create_chatbot():
    """
    CrÃ©e un chatbot LangChain basÃ© sur un index vectoriel.
    """
    print("ğŸ”„ Chargement de l'index vectoriel...")
    vector_store = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)

    print("âœ… Chatbot prÃªt Ã  l'emploi.")
    return ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(temperature=0, model="gpt-3.5-turbo", openai_api_key=OPENAI_API_KEY),
        retriever=vector_store.as_retriever()
    )

# ğŸ“Œ Fonction principale
def process_last_user_message():
    """
    Traite le dernier message utilisateur et gÃ©nÃ¨re une rÃ©ponse.
    """
    # RÃ©cupÃ©rer le dernier message utilisateur
    last_message = get_last_user_message()
    if not last_message:
        print("Aucun message utilisateur trouvÃ©.")
        return

    chat_id = last_message["chat_id"]
    user_message = last_message["content"]

    # Charger l'historique du chat
    history = get_chat_history(chat_id)

    # CrÃ©er le chatbot
    chatbot = create_chatbot()

    # GÃ©nÃ©rer une rÃ©ponse
    response = chatbot({"question": user_message, "chat_history": history})
    bot_response = response["answer"]
    print(f"RÃ©ponse gÃ©nÃ©rÃ©e : {bot_response}")

    # Sauvegarder la rÃ©ponse dans la base de donnÃ©es
    save_assistant_message(chat_id, bot_response)
    print("âœ… RÃ©ponse de l'assistant sauvegardÃ©e.")

# ğŸ“Œ ExÃ©cuter le script
if __name__ == "__main__":
    process_last_user_message()
